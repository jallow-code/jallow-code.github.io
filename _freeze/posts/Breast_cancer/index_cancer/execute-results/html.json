{
  "hash": "04b22db8de32c729aa3c3042efea7f71",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Exploring the Breast Cancer Dataset\"\nauthor:\n  - name: Abdoulie Jallow\n    url: https://jallow-code.github.io/\ndate: 12 01 2025\ncategories: [Learn, R] # self-defined categories\n---\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(data.table)\nlibrary(tidyverse)\nlibrary(psych)\nlibrary(corrplot)\nlibrary(caret)\nlibrary(pROC)\nlibrary(PRROC)\nlibrary(RColorBrewer)\n\nset.seed(12)\n```\n:::\n\n\n\n## Introduction\n\nThis blog is an exercise on classification methods using the Breast Cancer dataset which is sourced from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/dataset/15/breast+cancer+wisconsin+original). This dataset contains different variables used to classify tumors as either benign or malignant.\n\n## Exploratory Analysis and Preprocessing\n\nWe will start by reading the documentation of the dataset, which will tell us how the data is organized. For example, it may provide information on the number of variables and observations, how to interpret certain variables, how missing values are encoded, etc. We will then proceed to check for possible outliers, class imbalance, and the presence of redundant continuous variables.\n\n### Importing the Dataset\n\nAfter reading the documentation, we'll load the dataset into R and assign appropriate column names.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npath <- \"dataset/breast-cancer-wisconsin.data\"\n\ndata <- read.table(path, sep = \",\")\n\ncolnames(data) <- c(\"Sample_code_number\", \"Clump_thickness\",\n                    \"Uniformity_of_cell_size\", \"Uniformity_of_cell_shape\",\n                    \"Marginal_adhesion\", \"Single_epithelial_cell_size\",\n                    \"Bare_nuclei\", \"Bland_chromatin\", \"Mitoses\",\n                    \"Normal_nucleoli\", \"Class\")\n\nstr(data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n'data.frame':\t699 obs. of  11 variables:\n $ Sample_code_number         : int  1000025 1002945 1015425 1016277 1017023 1017122 1018099 1018561 1033078 1033078 ...\n $ Clump_thickness            : int  5 5 3 6 4 8 1 2 2 4 ...\n $ Uniformity_of_cell_size    : int  1 4 1 8 1 10 1 1 1 2 ...\n $ Uniformity_of_cell_shape   : int  1 4 1 8 1 10 1 2 1 1 ...\n $ Marginal_adhesion          : int  1 5 1 1 3 8 1 1 1 1 ...\n $ Single_epithelial_cell_size: int  2 7 2 3 2 7 2 2 2 2 ...\n $ Bare_nuclei                : chr  \"1\" \"10\" \"2\" \"4\" ...\n $ Bland_chromatin            : int  3 3 3 3 3 9 3 3 1 2 ...\n $ Mitoses                    : int  1 2 1 7 1 7 1 1 1 1 ...\n $ Normal_nucleoli            : int  1 1 1 1 1 1 1 1 5 1 ...\n $ Class                      : int  2 2 2 2 2 4 2 2 2 2 ...\n```\n\n\n:::\n:::\n\n\n\n### Missing Values and Variable Encoding\n\nThis dataset uses `\"?\"` to represent missing values. These need to be replaced with `NA` for proper handling in R. We then remove rows containing missing values. Additionally, some variables are encoded incorrectly and need to be transformed into their appropriate data types.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata[data == \"?\"] <- NA \ndata <- na.omit(data)   \n\ndata$Sample_code_number <- NULL\n\ndata$Class <- as.factor(ifelse(data$Class == 2, \"benign\", \"malignant\"))\n\ndata$Bare_nuclei <- as.integer(data$Bare_nuclei)\n\n\nstr(data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n'data.frame':\t683 obs. of  10 variables:\n $ Clump_thickness            : int  5 5 3 6 4 8 1 2 2 4 ...\n $ Uniformity_of_cell_size    : int  1 4 1 8 1 10 1 1 1 2 ...\n $ Uniformity_of_cell_shape   : int  1 4 1 8 1 10 1 2 1 1 ...\n $ Marginal_adhesion          : int  1 5 1 1 3 8 1 1 1 1 ...\n $ Single_epithelial_cell_size: int  2 7 2 3 2 7 2 2 2 2 ...\n $ Bare_nuclei                : int  1 10 2 4 1 10 10 1 1 1 ...\n $ Bland_chromatin            : int  3 3 3 3 3 9 3 3 1 2 ...\n $ Mitoses                    : int  1 2 1 7 1 7 1 1 1 1 ...\n $ Normal_nucleoli            : int  1 1 1 1 1 1 1 1 5 1 ...\n $ Class                      : Factor w/ 2 levels \"benign\",\"malignant\": 1 1 1 1 1 2 1 1 1 1 ...\n - attr(*, \"na.action\")= 'omit' Named int [1:16] 24 41 140 146 159 165 236 250 276 293 ...\n  ..- attr(*, \"names\")= chr [1:16] \"24\" \"41\" \"140\" \"146\" ...\n```\n\n\n:::\n:::\n\n\n\n::: callout-tip\nReading the dataset documentation is important for understanding how missing values and variables are encoded. For example, missing values in this dataset are not labeled as `NA` by default, and variables such as `Bare_nuclei` and `Class` needed to be converted to the appropriate data types (integer and factor, respectively).\n:::\n\n### Analyze the continuous variables\n\nTo identify redundant variables, we analyze correlations among continuous variables. High collinearity can negatively impact model performance. Hence, we can address this either by removing one of the variables or combind them into a new variable. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata_corr <- cor(data[, -10]) \n\npairs.panels(data_corr, cex.labels = 0.6, ellipses = FALSE)\n```\n\n::: {.cell-output-display}\n![](index_cancer_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\n\nThe variables `Uniformity_of_cell_size` and `Uniformity_of_cell_shape` are highly correlated. Here, we'll create a new variable, `Cell_morphology`, by randomly sampling values from these two columns row-wise.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata$Cell_Morphology <- apply(data[, c(\"Uniformity_of_cell_size\", \"Uniformity_of_cell_shape\")],\n                              MARGIN = 1, \n                              FUN = sample,\n                              size = 1)\n\ndata$Uniformity_of_cell_size <- NULL\ndata$Uniformity_of_cell_shape <- NULL\n\n\nstr(data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n'data.frame':\t683 obs. of  9 variables:\n $ Clump_thickness            : int  5 5 3 6 4 8 1 2 2 4 ...\n $ Marginal_adhesion          : int  1 5 1 1 3 8 1 1 1 1 ...\n $ Single_epithelial_cell_size: int  2 7 2 3 2 7 2 2 2 2 ...\n $ Bare_nuclei                : int  1 10 2 4 1 10 10 1 1 1 ...\n $ Bland_chromatin            : int  3 3 3 3 3 9 3 3 1 2 ...\n $ Mitoses                    : int  1 2 1 7 1 7 1 1 1 1 ...\n $ Normal_nucleoli            : int  1 1 1 1 1 1 1 1 5 1 ...\n $ Class                      : Factor w/ 2 levels \"benign\",\"malignant\": 1 1 1 1 1 2 1 1 1 1 ...\n $ Cell_Morphology            : int  1 4 1 8 1 10 1 1 1 1 ...\n - attr(*, \"na.action\")= 'omit' Named int [1:16] 24 41 140 146 159 165 236 250 276 293 ...\n  ..- attr(*, \"names\")= chr [1:16] \"24\" \"41\" \"140\" \"146\" ...\n```\n\n\n:::\n:::\n\n\n\n### Checking for Class Imbalance\n\nClass imbalance is a common issue in classification tasks. we analyze the distribution of the target variable (`Class`) to assess the extent of imbalance.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata |>\n  count(Class) |>\n  mutate(Percentage = round((n / nrow(data)) * 100, 2))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      Class   n Percentage\n1    benign 444      65.01\n2 malignant 239      34.99\n```\n\n\n:::\n:::\n\n\n\nThe dataset shows a mildly imbalanced distribution, with the minority class representing approximately 35% of the data. This level of imbalance typically does not significantly affect model performance, and models can often be trained directly on the original data. If the imbalance were severe, techniques such as upsampling or downsampling could be applied.\n\n### Splitting the Dataset\n\nTo prepare for model training, we split the dataset into training, validation, and test sets, allocating 70% of the data for training. We use cross-validation to ensure robust evaluation during model development.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntrain <- createDataPartition(data$Class, p = 0.7, list = FALSE)\n\ndata.trn <- data[train, ]\ndata.tst <- data[-train, ]\n\n\nctrl <- trainControl(method = \"cv\",         # K-Fold cross-validation\n                     number = 10,           # 10 folds\n                     returnResamp = 'none',\n                     classProbs = TRUE,   \n                     savePredictions = TRUE,\n                     summaryFunction = twoClassSummary)\n```\n:::\n\n\n\n## Modeling\n\nNext, we fit different classification models to predict whether a tumor is malignant or benign based on the variables. Finally, we will evaluate the models using their respective confusion matrices and other performance metrics.\n\n### Logistic regression\n\nLogistic regression is one of the simplest and most interpretable classification algorithms. We train the model using cross-validation and evaluate its performance on the test set.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglm.fit <- train(Class ~ .,         \n                 data = data.trn,               \n                 method = \"glm\",          # Generalized linear model\n                 family = \"binomial\",     # Logistic regression\n                 trControl = ctrl,              \n                 metric = \"ROC\")                 \n\nglm.pred <- predict(glm.fit, newdata = data.tst, type = \"prob\")\n\nglm.pred <- glm.pred[, 2]\n\nglm.class <- ifelse(glm.pred > 0.5, \"malignant\", \"benign\")\n\nlogistic_cm <- confusionMatrix(data = as.factor(glm.class),\n                               reference = as.factor(data.tst$Class),\n                               positive = \"malignant\")\nlogistic_cm\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nConfusion Matrix and Statistics\n\n           Reference\nPrediction  benign malignant\n  benign       130         3\n  malignant      3        68\n                                          \n               Accuracy : 0.9706          \n                 95% CI : (0.9371, 0.9891)\n    No Information Rate : 0.652           \n    P-Value [Acc > NIR] : <2e-16          \n                                          \n                  Kappa : 0.9352          \n                                          \n Mcnemar's Test P-Value : 1               \n                                          \n            Sensitivity : 0.9577          \n            Specificity : 0.9774          \n         Pos Pred Value : 0.9577          \n         Neg Pred Value : 0.9774          \n             Prevalence : 0.3480          \n         Detection Rate : 0.3333          \n   Detection Prevalence : 0.3480          \n      Balanced Accuracy : 0.9676          \n                                          \n       'Positive' Class : malignant       \n                                          \n```\n\n\n:::\n:::\n\n\n\nTo understand which features contribute most to the model, we use the `varImp()` function.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Identify and rank the most important variables\nvarImp(glm.fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nglm variable importance\n\n                            Overall\nBare_nuclei                  100.00\nClump_thickness               78.57\nCell_Morphology               28.26\nBland_chromatin               27.03\nSingle_epithelial_cell_size   24.21\nMitoses                       16.35\nNormal_nucleoli               10.58\nMarginal_adhesion              0.00\n```\n\n\n:::\n:::\n\n\n\n### K-Nearest Neighbors (KNN)\n\nKNN is a simple non-parametric method that predicts the class of a sample based on the majority class of its nearest neighbors.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nknn.fit <- train(Class ~ ., data = data.trn, method = \"knn\",\n  trControl = ctrl, \n  preProcess = c(\"center\",\"scale\"), \n  tuneGrid =data.frame(k=seq(5,100,by=5)),\n  metric = \"ROC\")\n  \n\nknn.pred <- predict(knn.fit, data.tst)\n\nknn_cm <- confusionMatrix(as.factor(knn.pred),\n                          reference =as.factor(data.tst$Class),\n                          positive = \"malignant\")\nknn_cm\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nConfusion Matrix and Statistics\n\n           Reference\nPrediction  benign malignant\n  benign       130         6\n  malignant      3        65\n                                          \n               Accuracy : 0.9559          \n                 95% CI : (0.9179, 0.9796)\n    No Information Rate : 0.652           \n    P-Value [Acc > NIR] : <2e-16          \n                                          \n                  Kappa : 0.9018          \n                                          \n Mcnemar's Test P-Value : 0.505           \n                                          \n            Sensitivity : 0.9155          \n            Specificity : 0.9774          \n         Pos Pred Value : 0.9559          \n         Neg Pred Value : 0.9559          \n             Prevalence : 0.3480          \n         Detection Rate : 0.3186          \n   Detection Prevalence : 0.3333          \n      Balanced Accuracy : 0.9465          \n                                          \n       'Positive' Class : malignant       \n                                          \n```\n\n\n:::\n\n```{.r .cell-code}\nplot(knn.fit)\n```\n\n::: {.cell-output-display}\n![](index_cancer_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\n\n### Linear Discriminant Analysis\n\nLDA assumes that the predictors follow a normal distribution and aims to maximize the separation between classes.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlda.fit <- train(Class ~ ., \n                 data = data.trn, \n                 method = \"lda\", \n                 trControl = ctrl, \n                 metric = \"ROC\")\n\n# Generate probabilities for LDA\nlda.pred <- predict(lda.fit, newdata = data.tst, type = \"prob\")\nlda.class <- ifelse(lda.pred[, \"malignant\"] > 0.5, \"malignant\", \"benign\")\n\n\nlda_cm <- confusionMatrix(data = as.factor(lda.class),\n                          reference = as.factor(data.tst$Class),\n                          positive = \"malignant\")\nlda_cm\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nConfusion Matrix and Statistics\n\n           Reference\nPrediction  benign malignant\n  benign       130         5\n  malignant      3        66\n                                          \n               Accuracy : 0.9608          \n                 95% CI : (0.9242, 0.9829)\n    No Information Rate : 0.652           \n    P-Value [Acc > NIR] : <2e-16          \n                                          \n                  Kappa : 0.913           \n                                          \n Mcnemar's Test P-Value : 0.7237          \n                                          \n            Sensitivity : 0.9296          \n            Specificity : 0.9774          \n         Pos Pred Value : 0.9565          \n         Neg Pred Value : 0.9630          \n             Prevalence : 0.3480          \n         Detection Rate : 0.3235          \n   Detection Prevalence : 0.3382          \n      Balanced Accuracy : 0.9535          \n                                          \n       'Positive' Class : malignant       \n                                          \n```\n\n\n:::\n:::\n\n\n\n### Quadradic Discriminant Analysis\n\nQDA is similar to LDA but allows for each class to have its own covariance matrix, making it more flexible for non-linear boundaries.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nqda.fit <- train(Class ~ ., \n                 data = data.trn, \n                 method = \"qda\", \n                 trControl = ctrl, \n                 metric = \"ROC\")\n\n\nqda.pred <- predict(qda.fit, newdata = data.tst, type = \"prob\")\nqda.class <- ifelse(qda.pred[, \"malignant\"] > 0.5, \"malignant\", \"benign\")\n\n\nqda_cm <- confusionMatrix(data = as.factor(qda.class),\n                          reference = as.factor(data.tst$Class),\n                          positive = \"malignant\")\nqda_cm\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nConfusion Matrix and Statistics\n\n           Reference\nPrediction  benign malignant\n  benign       122         0\n  malignant     11        71\n                                          \n               Accuracy : 0.9461          \n                 95% CI : (0.9056, 0.9728)\n    No Information Rate : 0.652           \n    P-Value [Acc > NIR] : < 2.2e-16       \n                                          \n                  Kappa : 0.8853          \n                                          \n Mcnemar's Test P-Value : 0.002569        \n                                          \n            Sensitivity : 1.0000          \n            Specificity : 0.9173          \n         Pos Pred Value : 0.8659          \n         Neg Pred Value : 1.0000          \n             Prevalence : 0.3480          \n         Detection Rate : 0.3480          \n   Detection Prevalence : 0.4020          \n      Balanced Accuracy : 0.9586          \n                                          \n       'Positive' Class : malignant       \n                                          \n```\n\n\n:::\n:::\n\n\n\n### Naive Bayes\n\nNaive Bayes is a probabilistic classifier based on Bayes' theorem, assuming independence among predictors.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnb.fit <- train(Class ~ ., \n                data = data.trn, \n                method = \"naive_bayes\", \n                trControl = ctrl, \n                metric = \"ROC\")\n\n\nnb.pred <- predict(nb.fit, newdata = data.tst, type = \"prob\")\n\n\nnb.class <- ifelse(nb.pred[, \"malignant\"] > 0.5, \"malignant\", \"benign\")\n\n\nnb_cm <- confusionMatrix(data = as.factor(nb.class),\n                         reference = as.factor(data.tst$Class),\n                         positive = \"malignant\")\nnb_cm\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nConfusion Matrix and Statistics\n\n           Reference\nPrediction  benign malignant\n  benign       124         0\n  malignant      9        71\n                                          \n               Accuracy : 0.9559          \n                 95% CI : (0.9179, 0.9796)\n    No Information Rate : 0.652           \n    P-Value [Acc > NIR] : < 2.2e-16       \n                                          \n                  Kappa : 0.9056          \n                                          \n Mcnemar's Test P-Value : 0.007661        \n                                          \n            Sensitivity : 1.0000          \n            Specificity : 0.9323          \n         Pos Pred Value : 0.8875          \n         Neg Pred Value : 1.0000          \n             Prevalence : 0.3480          \n         Detection Rate : 0.3480          \n   Detection Prevalence : 0.3922          \n      Balanced Accuracy : 0.9662          \n                                          \n       'Positive' Class : malignant       \n                                          \n```\n\n\n:::\n:::\n\n\n\n## Performance\n\n### AUC-ROC Curve Analysis\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# ---- Function to calculate and return the ROC curves for a given mode -------\ncalculate_roc <- function(model, test_data, response_var, positive_class, predictor_type = \"prob\") {\n  \n  # Generate predicted probabilities\n  pred_probs <- predict(model, newdata = test_data, type = predictor_type)\n  \n  # Ensure the response variable is a factor with correct levels\n  response <- test_data[[response_var]]\n  \n  # Calculate ROC curve\n  roc_curve <- roc(\n    response = response,\n    predictor = pred_probs[, positive_class], # Probability for the positive class\n    levels = levels(response),\n    direction = \"<\"  # Higher values indicate the positive class\n  )\n  \n  return(roc_curve)\n}\n\n# ---- Calculate ROC curves for all models -------\n# Logistic Regression\nroc_glm <- calculate_roc(\n  model = glm.fit,\n  test_data = data.tst,\n  response_var = \"Class\",\n  positive_class = \"malignant\"\n)\n\n# KNN\nroc_knn <- calculate_roc(\n  model = knn.fit,\n  test_data = data.tst,\n  response_var = \"Class\",\n  positive_class = \"malignant\"\n)\n\n# LDA\nroc_lda <- calculate_roc(\n  model = lda.fit,\n  test_data = data.tst,\n  response_var = \"Class\",\n  positive_class = \"malignant\")\n\n\n# QDA\nroc_qda <- calculate_roc(\n  model = qda.fit,\n  test_data = data.tst,\n  response_var = \"Class\",\n  positive_class = \"malignant\"\n)\n\n# Naive Bayes\nroc_nb <- calculate_roc(\n  model = nb.fit,\n  test_data = data.tst,\n  response_var = \"Class\",\n  positive_class = \"malignant\"\n)\n\n# Extract AUC values\nauc_glm <- round(auc(roc_glm), 2)\nauc_knn <- round(auc(roc_knn), 2)\nauc_lda <- round(auc(roc_lda), 2)\nauc_qda <- round(auc(roc_qda), 2)\nauc_nb <- round(auc(roc_nb), 2)\n\n# ------ Graph --------\npar(pty = \"s\") # Set square aspect ratio\n\n# Plot ROC Curves\nplot(roc_glm, col = \"#1B9E77\", lwd = 3, percent = TRUE,\n     main = \"ROC Curve Comparison\",\n     xlab = \"False Positive rate\", \n     ylab = \"True Positive rate\", \n     legacy.axes = TRUE)\n\nplot(roc_knn, col = \"#D95F02\", lwd = 3, percent = TRUE, add = T)\n\nplot(roc_lda, col = \"#7570B3\", lwd = 3, percent = TRUE, add = T)\n\nplot(roc_qda, col = \"#E7298A\", lwd = 3, percent = TRUE, add = T)\n\nplot(roc_nb, col = \"#66A61E\", lwd = 3, percent = TRUE, add = T)\n\n# Add Legend with AUC values\nlegend(\"bottomright\", \n       legend = c(\n         paste(\"Logistic (AUC =\", auc_glm, \")\"),\n         paste(\"KNN (AUC =\", auc_knn, \")\"),\n         paste(\"LDA (AUC =\", auc_lda, \")\"),\n         paste(\"QDA (AUC =\", auc_qda, \")\"),\n         paste(\"Naive Bayes (AUC =\", auc_nb, \")\")\n       ), \n       col = c(\"#1B9E77\", \"#D95F02\", \"#7570B3\", \"#E7298A\", \"#66A61E\"), \n       lwd = 2)\n```\n\n::: {.cell-output-display}\n![](index_cancer_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n\n```{.r .cell-code  code-fold=\"true\"}\n# Reset par() variables\npar(pty = \"m\")\n```\n:::\n\n\nThe AUC-ROC curves show how well each model can discriminate between malignant and benign at all classification thresholds. An AUC of 1.0 indicates a perfect classifier that can distinguish between the two classes without error. Logistic regression and KNN achieved an AUC of 1, indicating perfect classification performance. LDA, QDA, and Naive Bayes also performed well with AUC values close to 1.\n\n\n### Precision Recall Curve\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# Correct Precision-Recall Curve Plotting with PRROC\nplot_pr_curve <- function(model, test_data, true_labels, positive_class, add = FALSE, color = \"blue\") {\n  # Generate predicted probabilities for the positive class\n  pred_probs <- predict(model, newdata = test_data, type = \"prob\")[, positive_class]\n  \n  # Generate PR curve\n  pr <- pr.curve(scores.class0 = pred_probs, \n                 weights.class0 = ifelse(true_labels == positive_class, 1, 0), \n                 curve = TRUE)\n  \n  # Plot PR curve\n  plot(pr, main = \"Precision-Recall Curve \", add = add, col = color, auc.main = FALSE, legend = FALSE)\n  \n  # Return AUC value\n  return(pr$auc.integral)\n}\n\n# Generate PR Curves for All Models\npr_aucs <- c(\n  Logistic = plot_pr_curve(glm.fit, data.tst, data.tst$Class, \"malignant\", color = \"#1B9E77\"),\n  KNN = plot_pr_curve(knn.fit, data.tst, data.tst$Class, \"malignant\", add = TRUE, color = \"#D95F02\"),\n  LDA = plot_pr_curve(lda.fit, data.tst, data.tst$Class, \"malignant\", add = TRUE, color = \"#7570B3\"),\n  QDA = plot_pr_curve(qda.fit, data.tst, data.tst$Class, \"malignant\", add = TRUE, color = \"#E7298A\"),\n  NaiveBayes = plot_pr_curve(nb.fit, data.tst, data.tst$Class, \"malignant\", add = TRUE, color = \"#66A61E\")\n)\n\n# Add Legend with AUC\nlegend(\"bottomleft\", \n       legend = paste(names(pr_aucs), \"(AUC =\", round(pr_aucs, 2), \")\"), \n       col = c(\"#1B9E77\", \"#D95F02\", \"#7570B3\", \"#E7298A\", \"#66A61E\"), \n       lty = 1, cex = 0.8, lwd = 2)\n```\n\n::: {.cell-output-display}\n![](index_cancer_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n\n\nSince the dataset is imbalanced, the false positive rate in the ROC-AUC curve is often replaced with precision to better evaluate model performance. In this context, the minority class (malignant) is important, so we prioritize models that effectively minimize false negatives. Logistic regression, KNN, and LDA all have AUC of 0.99 while QDA and Naive bayes performs slightly lower.\n\n### Accuracy\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n        #----- Data frame of model performance metrics --------\n\nmodel_data <- data.frame(\n  Model = c(\"Logistic Regression\", \"KNN\", \"LDA\", \"QDA\",\n            \"Naive Bayes\"),\n   # accuracy values\n  accuracy = c(logistic_cm$overall[\"Accuracy\"],\n               knn_cm$overall[\"Accuracy\"],\n               lda_cm$overall[\"Accuracy\"],\n               qda_cm$overall[\"Accuracy\"],\n               nb_cm$overall[\"Accuracy\"]),\n   # Lower confidence interval\n  Lower = c(logistic_cm$overall[\"AccuracyLower\"],\n            knn_cm$overall[\"AccuracyLower\"],\n            lda_cm$overall[\"AccuracyLower\"],\n            qda_cm$overall[\"AccuracyLower\"],\n            nb_cm$overall[\"AccuracyLower\"]),\n  # Upper confidence interval\n  Upper = c(logistic_cm$overall[\"AccuracyUpper\"],\n            knn_cm$overall[\"AccuracyUpper\"],\n            lda_cm$overall[\"AccuracyUpper\"],\n            qda_cm$overall[\"AccuracyUpper\"],\n            nb_cm$overall[\"AccuracyUpper\"]))\n  \n\n                #----- plot -----\n\nggplot(model_data, aes(x = accuracy, y = Model)) +\n  geom_point(size = 3, color = \"blue\") +\n  geom_errorbarh(aes(xmin = Lower, xmax = Upper), height = 0.2, color = \"blue\") +\n  labs(title = \"\",\n       x = \"Accuracy\",\n       y = \"\") +\n  scale_x_continuous(limits = c(0.88, 1)) + \n  theme_minimal() +\n  theme(panel.grid.major.y = element_blank(),\n        panel.grid.minor = element_blank(),\n        axis.text.y = element_text(size = 12),\n        plot.title = element_text(hjust = 0.5))\n```\n\n::: {.cell-output-display}\n![](index_cancer_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n\n\nAccuracy provides a direct (baseline) measure of model performance on correctly classified instances. All the models performed well on this metric.\n\n## Conclusion\n\nLogistic Regression consistently outperformed other models across all metrics, hence emerges as the preferred model for this dataset.\n",
    "supporting": [
      "index_cancer_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}